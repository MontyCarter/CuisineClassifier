\documentclass[11pt]{article}

\usepackage[letterpaper]{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[utf8]{inputenc}
\usepackage{url}
\newcommand{\reals}{{\mathbb R}}

\title{Interim report\\CS6350 Machine Learning}
\author{Montgomery Carter \and Shaobo He}


\begin{document}
\maketitle

\section{Recap}
The goal of our proposed project is to predict the cuisine type of a
recipe based on the recipe's ingredient list\cite{kaggle-link}.  In
the dataset we are given a list of recipes.  For each recipe we are
given cuisine type and a list of ingredients.

\section{Milestones Achieved}
\label{sec:background}
%\begin{enumerate}
Our first task was to acquire the training and test
data\cite{download-link} from kaggle.com and ensure its formatting
was proper for machine processing.

Next we wrote a python program to read the data stored in JSON format
and convert it into a vector data structure so that it can be
processed smoothly by machine learning algorithms. To be more 
specific, each recipe becomes a vector where each dimension represents
a possible ingredient.  If the dimension's value is 0, the ingredient
is not present in the recipe; if the value is 1, the ingredient is
present in the recipe.  The final dimension of the vector is the
label.  Because we are dealing with multiple cuisines, we have a
multi-class classification problem (which is addressed in further
detail below).  For now, we mapped each possible cuisine to an integer
value, and this value is inserted as the last dimension in each recipe
vector.  We recognize that when we get further into analysis using
specific algorithms, it is likely that we will have to change the
representation of the label. 

Having transformed the data, we also did some preliminary analysis of
the data.  For example, we noticed that there are about 6000 different
possible ingredients (meaning 6000 dimensions per vector), which may
prove to be a challenge for linear classification.  However, we also
noticed that there are a number of different ingredients which seem to
be only slight spelling variations of the same actual ingredient.
Condensing such variants into a single ingredient may help with
reducing dimensionality.

We realize that perhaps our biggest obstacle with this project is
going to be the multi-class classification.  We haven't really
addressed such algorithms in class, so we are reading about ways to
address multi-class classification.\cite{wiki}
%\end{enumerate}


\section{Plan}
\label{sec:plan}

The first thing of our plan is to refine the data so it can be processed more accurately by machine learning algorithms. The reason of this input data refinement is that
we notice that there are around $6000$ sorts of ingredients in our training data set, which can make it hard for K nearest neighbor algorithm to classify the data set.
Moreover, duplicate ingredients exists with spelling variantions so we should be able to remove the naming redudancy and thus reduce the dimensionality of the training data set.

The next step is to apply machine learning algorithms on the training set. The first algorithm we would like to try is decision tree since it is a simple algorithm to learn data with multiple labels. Another reason is that we noticed that many ingredients are only associated with one individual cuisine. Thus it may be easy for decision tree to generalize the training data.

If decision tree does not work well, then we will turn to algorithms that convert the problem of multi-class classification into multiple binary-class classification problems. For instance, we can try one-vs-one multi-class classification\cite{wiki} and one-vs-res multi-class classification\cite{wiki}.  
%\begin{enumerate}
%\item Need to decide on algorithm
%\item Try one-vs-one multi-class classification
%\item Try one-vs-res multi-class classification
%\item Try other possible ways of doing multi-class classification (if any) 
%\end{enumerate}

%\newpage
\bibliography{refs}
\bibliographystyle{plain}
\end{document}
