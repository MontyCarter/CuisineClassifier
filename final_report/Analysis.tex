\section{Analysis}
The general lesson that we learned from this project is machine
learning is not easy, specially for multi-class
classification. Looking at the results shown in Table 1, it is clear
that we reached a limit on accuracy (around 80\%). Our guess for such
limit is that multiple cuisines may share the same set of ingredients
as mentioned in Section 2. For example, a large proportion of
ingredients from Asian cuisines is the same. A direct implication of
ingredient similarity among cuisines is that data set is not linearly
separable. Even with feature transformation implemented by SVM with
non-linear kernels, we were not be able to improve the performance of
classifiers. Also some recipes only contain common ingredients such as
salt, water, and butter, which makes prediction impossible. 

Moreover, we also learned that complexity of machine learning
algorithms matters. One can see that runtime as well as accuracy of
SVM algorithms is proportional to the complexity of their kernels. We
would expect longer runtime if we increase the degree of polynomial
kernels. %Therefore, a trade-off between runtime (probably accuracy)
%and algorithm complexity can be explore $<$not sure what you're trying
%to say here$>$.
We also noticed resource
limits are also an important factor to consider when we choose machine
learning algorithms. We encountered out of memory exceptions when
running K-nearest neighbor algorithm even used sparse matrix that
reduces the size of input data significantly compared to dense
array. As a result, we had to reduce the number of processes executing
concurrently, and thus were not be able to fully utilize the computing
capacity of powerful Emulab machines. 

For the rest of the section, we give our analysis on machine learning
algorithms that we tried in this project with a focus on why some of
them works while others do not. 

\paragraph{SVM} SVM gives us best accuracy despite its long
runtime. We think indicator ingredients probably contribute to it
because intuitively they tend to increase the margin and make the data
more linearly separable. Note that the polynomial and Gaussian kernels
do not improve the accuracy a lot, which means that boundaries among 
cuisines is approximately linear and we thus could possibly improve prediction
accuracy by pruning the dataset to make it more linear separable. %$<$I don't understand this sentence$>$

\paragraph{Probabilistic learning} After some analysis on statistics
that we gathered from the data set, we found it straight forward to
explain why the accuracy of probabilistic learning is comparable to
the that of SVM algorithms. Recall that the prediction rule for naive Bayes
classifier is $argmax_y \Pr(Y)\prod_{i} \Pr(x_i|Y)$, which means that
if a cuisine has some indicator ingredients (the probability that it
belongs to a certain cuisine is high), then it is highly likely to be
predicted correctly. It corresponds to our observation that the top
five ingredients as a whole set of 20 cuisines are exclusive . %$<$I said the
%OPPOSITE of this statement (top 5 ingreds largely overlap...  Sugar,
%salt, butter, flour...  We need to reconcile this discrepancy.$>$
 
\paragraph{Ensemble methods} Ensemble methods with decision trees as
weak learners, indeed, proved to be helpful.  The ensemble methods
clearly help to boost the accuracy of decision trees and stumps.  Our
attempt at using AdaBoost with SVM proved to not be terribly useful,
however, our implementation didn't provide a mechanism to
cross-validate through an extra layer of algorithms, so we weren't
able to test many combinations of hyper parameters for SVM as the base
estimator.  


\paragraph{Those that do not work well} Decision trees are known to
overfit the training set. We tried to mitigate overfitting by setting
up a depth limit, however, the accuracy was not improved. For K nearest
neighbors, we found it confusing because theoretically it is very
expressive and thus should be able to provide high accuracy. Our
assumption is that we might not choose the best distance
measurement. We only used Euclidean distance instead of trying other
distance measurement due to unavailability of these metrics in sci-kit
library.  Another hypothesis for the lack of accuracy with KNN is that
we didn't have enough examples to fully characterize each cuisine.