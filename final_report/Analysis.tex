\section{Analysis}
The general lesson that we learned from this project is machine learning is not easy, specially for multi-class classification. Looking at the results shown in table 1, it is clear that we reached a limit on accuracy (around 80\%). Our guess for such limit is that multiple cuisines may share the same set of ingredients as mentioned in the previous section. For example, a large proportion of ingredients from Asian cuisines is the same. A direct implication of ingredient similarity among cuisines is that data set is not linearly separable. Even with feature transformation implemented by SVM with non-linear kernels, we were not be able to improve the performance of classifiers. Also some recipes only contain common ingredients such as salt, water, and butter, which makes prediction even harder.

Moreover, we also learned that complexity of machine learning algorithms matters. One can see that runtime as well as accuracy of SVM algorithms is proportional to the complexity of their kernels. We would expect longer runtime if we increase the degree of polynomial kernels. Therefore, a trade-off between runtime (probably accuracy) and algorithm complexity can be explore. We also noticed resource limit is also an important factor to consider when we choose machine learning algorithms. We encountered out of memory exceptions when running K-nearest neighbor algorithm even used sparse matrix that reduces the size of input data significantly compared to dense array. As a result, we had to reduce the number of processes and thus were not be able to fully utilize the computing capacity of powerful Emulab machines.

For the rest of the section, we give our analysis on machine learning algorithms that we tried in this project with a focus on why some of them works while others do not.

\paragraph{SVM} SVM gives us best accuracy albeit its long runtime. We think indicator ingredients probably contribute to it because intuitively they tend to increase the margin and make dataset more linearly separable. Note that polynomial and Gaussian kernel does not improve the accuracy a lot, which means that boundaries among cuisines is approximately linear and we could improve prediction accuracy after pruning the data. 

\paragraph{Probabilistic learning} After some analysis on statistics that we gathered from the data set, we found it straight forward to explain why the performance of probabilistic learning is comparable to the best we have. Recall that the prediction rule for naive Bayes classifier is $argmax_y \Pr(Y)\prod_{i} \Pr(x_i|Y)$, which means that if a cuisine has some indicator ingredients (the probability that it belongs to a certain cuisine is high), then it is highly likely to be predicted correctly. It corresponds to our observation that the top five ingredients of 20 cuisines are mostly different.
 
\paragraph{Ensemble methods} Ensemble methods with decision trees as weak learners are proved to be effective according to the result. We think the reason why it works is explained in class while we cannot give a reasonable explanation on why the accuracy of AdaBoost with SVC is low.

\paragraph{Those that do not work well} Decision trees are known to overfit the training set. We tried to mitigate overfitting by setting up a depth limit while the accuracy was not improved. For K nearest neighbor, we found it confusing because theoretically it is very expressive and thus should be able to provide high accuracy. Our assumption is that we might not choose the best distance measurement. We only used Euclidean distance instead of trying other distance measurement due to lack of efficient implementation of these algorithms in sci-kit library.